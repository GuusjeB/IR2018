{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will use network-based algorithms, such as PageRank, to improve our search results. After the last assignment on evaluating IR systems, we go back to our PubMed dataset of scientific papers. In this dataset, we look at two graphs in particular: the co-authorship network and the citation network.\n",
    "\n",
    "The citation network is similar to the link network of the web: Citations are like web links pointing to other documents. We can therefore apply the same network-based ranking methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from previous assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2\n",
    "from collections import defaultdict, namedtuple, Counter\n",
    "from math import log10, sqrt\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show plots inline within the notebook\n",
    "%matplotlib inline\n",
    "# set plots' resolution\n",
    "plt.rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids_file = 'data/tree_Ids.pkl.bz2'\n",
    "Summaries_file = 'data/tree_Summaries.pkl.bz2'\n",
    "Citations_file = 'data/tree_Citations.pkl.bz2'\n",
    "Abstracts_file = 'data/tree_Abstracts.pkl.bz2'\n",
    "\n",
    "Ids = pickle.load( bz2.BZ2File( Ids_file, 'rb' ) )\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "Citations = pickle.load( bz2.BZ2File( Citations_file, 'rb' ) )\n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/%s>%s</a>' % (s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>%s</em></small>' % Abstracts[id])\n",
    "    if (show_id):\n",
    "        lines.append('[ID: %d]' % id)\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for (id, abstract) in Abstracts.items():\n",
    "    for term in preprocess(tokenize(abstract)):\n",
    "        inverted_index[term].add(id)\n",
    "\n",
    "tf_matrix = defaultdict(Counter)\n",
    "\n",
    "for (doc_id, abstract) in Abstracts.items():\n",
    "    tokens = preprocess(tokenize(abstract))\n",
    "    tf_matrix[doc_id] = Counter(tokens)\n",
    "\n",
    "def tf(t,d):\n",
    "    return float(tf_matrix[d][t])\n",
    "\n",
    "def df(t):\n",
    "    return float(len(inverted_index[t]))\n",
    "\n",
    "num_documents = float(len(Abstracts))\n",
    "\n",
    "def idf(t):\n",
    "    return log10(num_documents/df(t))\n",
    "\n",
    "def tfidf(t,d):\n",
    "    return tf(t,d) * idf(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-authorship network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by building a mapping from authors to the set of identifiers of papers they authored.  We'll be using Python's [sets](http://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset) again for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_of_author = defaultdict(set)\n",
    "\n",
    "for (id, p) in Summaries.items():\n",
    "    for a in p.authors:\n",
    "        papers_of_author[a].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16926492, 26164684, 27981465, 29047249, 30226902}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_of_author['Kwon Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1186/s13104-015-1265-y>Fatal non-thrombotic pulmonary embolization in a patient with undiagnosed factitious disorder.</a></strong><br>2015. Kwon Y, Koene RJ, Cross C, McEntee J, Green JS<br>[ID: 26164684]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.3349/ymj.2017.58.6.1229>A Personalized and Learning Approach for Identifying Drugs with Adverse Events.</a></strong><br>2017. Shin SK, Hur H, Cheon EK, Oh OH, Lee JS, Ko WJ, Kim BS, Kwon Y<br>[ID: 29047249]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1371/journal.pone.0203881>Tree species richness predicted using a spatial environmental model including forest area and frost frequency, eastern USA.</a></strong><br>2018. Kwon Y, Larsen CPS, Lee M<br>[ID: 30226902]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1007/s10661-016-5745-x>Area-based fuzzy membership forest cover comparison between MODIS NPP and Forest Inventory and Analysis (FIA) across eastern U.S. forest.</a></strong><br>2017. Kwon Y, Baker BW<br>[ID: 27981465]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1271/bbb.50608>Memory-enhancing effect of a supercritical carbon dioxide fluid extract of the needles of Abies koreana on scopolamine-induced amnesia in mice.</a></strong><br>2006. Kim K, Bu Y, Jeong S, Lim J, Kwon Y, Cha DS, Kim J, Jeon S, Eun J, Jeon H<br>[ID: 16926492]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for id in papers_of_author['Kwon Y']:\n",
    "    display_summary(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build a co-authorship network, that is a graph linking authors to the set of co-authors they have published with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthors = defaultdict(set)\n",
    "\n",
    "for p in Summaries.values():\n",
    "    for a in p.authors:\n",
    "        coauthors[a].update(p.authors)\n",
    "\n",
    "# The code above results in each author being listed as having co-authored with himself/herself.\n",
    "# We remove these self-references here:\n",
    "for (a, ca) in coauthors.items():\n",
    "    ca.remove(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try it out again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koene RJ, Oh OH, Lim J, Eun J, Bu Y, Jeon S, Jeong S, Cheon EK, Hur H, Lee JS, Kim J, Shin SK, Cha DS, Baker BW, Lee M, McEntee J, Kim K, Kim BS, Cross C, Green JS, Larsen CPS, Ko WJ, Jeon H\n"
     ]
    }
   ],
   "source": [
    "print(', '.join( coauthors['Kwon Y'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike a citation or link network, the edges of this co-authorship network are not directed: There is no direction (no arrow) in the link between author 'Kwon Y' and 'Koene RJ', for example. With our chosen implementation, each of these links in fact appears twice in our data, as we also get 'Kwon Y' as co-author when we look for 'Koene RJ':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koene RJ, Oh OH, Lim J, Eun J, Bu Y, Jeon S, Jeong S, Cheon EK, Hur H, Lee JS, Kim J, Shin SK, Cha DS, Baker BW, Lee M, McEntee J, Kim K, Kim BS, Cross C, Green JS, Larsen CPS, Ko WJ, Jeon H\n"
     ]
    }
   ],
   "source": [
    "print(', '.join( coauthors['Kwon Y'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in mind, we can calculate some basic statistics about our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes (authors):  217629\n",
      "Number of links (co-authorship relations):  1512946\n"
     ]
    }
   ],
   "source": [
    "print('Number of nodes (authors): ', len(coauthors))\n",
    "\n",
    "# We divide by two here to account for the fact that each edge is represented twice (see above):\n",
    "coauthor_rel_count = int(sum( len(c) for c in coauthors.values() ) / 2)\n",
    "print('Number of links (co-authorship relations): ', coauthor_rel_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data at hand, we can plot the [degree distribution](https://en.wikipedia.org/wiki/Degree_distribution) by showing the number of collaborators a scientist has published with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGhqTiiRpaEwqkqShMalIkobm/wMhQbs0An2oAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf81684748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( x=[ len(ca) for ca in coauthors.values() ], bins=range(60) )\n",
    "plt.xlabel('number of co-authors')\n",
    "plt.ylabel('number of researchers')\n",
    "plt.xlim(0,51);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have explored this network, let's move to the citation network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can look at the citation network. In contrast to the co-authorship network, the citation network is a _directed_ network, where edges can be drawn as arrows. We'll start by expanding the our data about citations into two mappings: \n",
    "\n",
    "* `papers_citing[id]`: papers citing a given paper\n",
    "* `cited_by[id]`: papers cited by a given paper (in other words: its list of references)\n",
    "\n",
    "`papers_citing` will give us the list of a node's incoming links, whereas `cited_by` will give us the list of its outgoing links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_citing = Citations  # no changes needed, this is what we are storing already in the Citations dataset\n",
    "\n",
    "cited_by = defaultdict(list)\n",
    "\n",
    "for ref, papers_citing_ref in papers_citing.items():\n",
    "    for id in papers_citing_ref:\n",
    "        cited_by[ id ].append( ref )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are dealing with a subset of the data (the papers mentioning \"aspirin\"), `papers_citing` can contain references to papers outside of our subset. On the other hand, the way we created `cited_by`, it will only contain backward references from within our dataset, meaning that it is incomplete with respect to the whole dataset. Nethertheless, we can use this citation network on our subset of aspirin-related papers to implement link analysis techniques.\n",
    "\n",
    "Let us now look at an exemlary paper, let's say the one with identifier 24130474. We can now use the `cited_by` mapping to retrieve its (incomplete) list of references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 references found for paper 26164684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id = 26164684\n",
    "refs = { id : Summaries[id].title for id in cited_by[paper_id] }\n",
    "print(len(refs), 'references found for paper', paper_id)\n",
    "refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we lookup the same paper in `papers_citing`, we now see that some of the cited papers are themselves in our dataset, but others are not (shown below as `'??'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ id : Summaries.get(id,['??'])[0]  for id in papers_citing[paper_id] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper 18931343, for example, is not in our dataset and we do not have any direct information about it, but its repeated occurrence in other papers' citation lists does allow us to reconstruct some of its references. Below is the list of papers in our dataset cited by that paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 references identified for the paper with id 18931343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id2 = 18931343\n",
    "refs2 = { id : Summaries[id].title for id in cited_by[paper_id2] }\n",
    "print(len(refs2), 'references identified for the paper with id', paper_id2)\n",
    "refs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better understanding about the data we're dealing with, let us obtain again some basic statistics about our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in our subset: 82791 (100.00 %)\n",
      "Number of papers cited at least once: 53193 (64.25 %)\n",
      "Number of isolated nodes: 26154 (31.59 %)\n"
     ]
    }
   ],
   "source": [
    "n = len(Ids)\n",
    "print('Number of papers in our subset: %d (%.2f %%)' % (n, 100.0) )\n",
    "\n",
    "with_citation = [ id for id in Ids if papers_citing[id] != [] ]\n",
    "with_citation_rel = 100. * len(with_citation) / n\n",
    "print('Number of papers cited at least once: %d (%.2f %%)' % (len(with_citation), with_citation_rel) )\n",
    "\n",
    "isolated = set( id for id in Ids if papers_citing[id] == [] and id not in cited_by )\n",
    "isolated_rel = 100. * len(isolated) / n\n",
    "print('Number of isolated nodes: %d (%.2f %%)' % (len(isolated), isolated_rel) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall number of nodes: 381580 (100.00 %)\n",
      "Number of non-isolated nodes: 355426 (93.15 %)\n",
      "Number of nodes outside our subset: 298789 (78.30 %)\n"
     ]
    }
   ],
   "source": [
    "id_set = set( Ids )\n",
    "citing_set = set( cited_by.keys() )\n",
    "\n",
    "outsiders = citing_set - id_set   # set difference\n",
    "nodes = citing_set | id_set   # set union\n",
    "non_isolated = nodes - isolated   # set difference\n",
    "\n",
    "print('Overall number of nodes: %d (%.2f %%)' % (len(nodes), 100.0) )\n",
    "\n",
    "non_isolated_rel = 100. * len(non_isolated) / len(nodes)\n",
    "print('Number of non-isolated nodes: %d (%.2f %%)' % (len(non_isolated), non_isolated_rel) )\n",
    "\n",
    "outsiders_rel = 100. * len(outsiders) / len(nodes)\n",
    "print('Number of nodes outside our subset: %d (%.2f %%)' % ( len(outsiders), outsiders_rel ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overal number of links (citations): 583171 (100.00 %)\n",
      "Citations from outside the subset: 506738 (86.89 %)\n"
     ]
    }
   ],
   "source": [
    "all_citations = [ c for citing in papers_citing.values() for c in citing ]\n",
    "outsider_citations = [ c for citing in papers_citing.values() for c in citing if c in outsiders ]\n",
    "\n",
    "print('Overal number of links (citations): %d (%.2f %%)' % (len(all_citations), 100.0) )\n",
    "\n",
    "outsider_citations_rel = 100. * len(outsider_citations) / len(all_citations)\n",
    "print('Citations from outside the subset: %d (%.2f %%)' % (len(outsider_citations), outsider_citations_rel) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now find our which 10 papers are the most cited in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/molbev/msr121>MEGA5: molecular evolutionary genetics analysis using maximum likelihood, evolutionary distance, and maximum parsimony methods.</a></strong><br>2011. Tamura K, Peterson D, Peterson N, Stecher G, Nei M, Kumar S<br>[ID: 21546353]<br>Citation count: 9094"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/nar/gkh340>MUSCLE: multiple sequence alignment with high accuracy and high throughput.</a></strong><br>2004. Edgar RC<br>[ID: 15034147]<br>Citation count: 8492"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/oxfordjournals.molbev.a040454>The neighbor-joining method: a new method for reconstructing phylogenetic trees.</a></strong><br>1987. Saitou N, Nei M<br>[ID: 3447015]<br>Citation count: 7379"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/molbev/msm092>MEGA4: Molecular Evolutionary Genetics Analysis (MEGA) software version 4.0.</a></strong><br>2007. Tamura K, Dudley J, Nei M, Kumar S<br>[ID: 17488738]<br>Citation count: 5985"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>A simple, fast, and accurate algorithm to estimate large phylogenies by maximum likelihood.</strong><br>2003. Guindon S, Gascuel O<br>[ID: 14530136]<br>Citation count: 4076"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>The American Rheumatism Association 1987 revised criteria for the classification of rheumatoid arthritis.</strong><br>1988. Arnett FC, Edworthy SM, Bloch DA, McShane DJ, Fries JF, Cooper NS, Healey LA, Kaplan SR, Liang MH, Luthra HS<br>[ID: 3358796]<br>Citation count: 3536"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/sysbio/syq010>New algorithms and methods to estimate maximum-likelihood phylogenies: assessing the performance of PhyML 3.0.</a></strong><br>2010. Guindon S, Dufayard JF, Lefort V, Anisimova M, Hordijk W, Gascuel O<br>[ID: 20525638]<br>Citation count: 2909"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1186/1471-2148-7-214>BEAST: Bayesian evolutionary analysis by sampling trees.</a></strong><br>2007. Drummond AJ, Rambaut A<br>[ID: 17996036]<br>Citation count: 2863"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/sysbio/sys029>MrBayes 3.2: efficient Bayesian phylogenetic inference and model choice across a large model space.</a></strong><br>2012. Ronquist F, Teslenko M, van der Mark P, Ayres DL, Darling A, Höhna S, Larget B, Liu L, Suchard MA, Huelsenbeck JP<br>[ID: 22357727]<br>Citation count: 2097"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1371/journal.pone.0009490>FastTree 2--approximately maximum-likelihood trees for large alignments.</a></strong><br>2010. Price MN, Dehal PS, Arkin AP<br>[ID: 20224823]<br>Citation count: 1594"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "citation_count_per_paper = [ (id, len(citations)) for (id,citations) in papers_citing.items() ]\n",
    "sorted_by_citation_count = sorted(citation_count_per_paper, key=lambda i:i[1], reverse=True)\n",
    "\n",
    "for (id, c) in sorted_by_citation_count[:10]:\n",
    "    display_summary(id, extra_text = 'Citation count: ' + str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start calculating some interesting network metrics, we will first have a closer look at the Python package that we are going to use for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Analysis for Search Engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the citation network, we need to be able to perform some complex graph algorithms on it. To make our lives easier, we will use [NetworkX](https://pypi.python.org/pypi/networkx), a Python package for dealing with complex networks. You might have to [install the NetworkX package](https://pypi.python.org/pypi/networkx) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (1.11)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph(cited_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a NetworkX Directed Graph stored in `G`, where a node represents a paper, and an edge represents a citation. This means we can now apply the [algorithms](http://networkx.github.io/documentation/networkx-1.10/reference/algorithms.html) and [functions](http://networkx.github.io/documentation/networkx-1.10/reference/functions.html) of NetworkX to our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 355426\n",
      "Number of edges: 583171\n",
      "Average in degree:   1.6408\n",
      "Average out degree:   1.6408\n",
      "Directed graph: True\n",
      "Density of graph: 4.616350261567263e-06\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))\n",
    "print('Directed graph:', nx.is_directed(G))\n",
    "print('Density of graph:', nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this graph was generated from citations only, we need to add all isolated nodes (nodes that are not cited and do not cite other papers) as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(isolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we get slightly different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 381580\n",
      "Number of edges: 583171\n",
      "Average in degree:   1.5283\n",
      "Average out degree:   1.5283\n",
      "Directed graph: True\n",
      "Density of graph: 4.005215147793839e-06\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))\n",
    "print('Directed graph:', nx.is_directed(G))\n",
    "print('Density of graph:', nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use this package for our tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Plot the in-degree distribution (that is, the distribution of the number of incoming links; see [here](https://en.wikipedia.org/wiki/Degree_distribution) and [here](http://mathinsight.org/degree_distribution) for more detailed explanations) for the citation network. What can you tell about the shape of this distribution, and what does this tell us about the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** [_Write your answer text here_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Using the [Link Analysis](https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.link_analysis.html) algorithms provided by NetworkX, calculate the PageRank score for all nodes in the citation network, and store the result in a variable called `pageranks`. Print out the PageRank values for the two example papers given below.\n",
    "You can also use the `pagerank_scipy` implementation, which tends to be considerably faster than its regular `pagerank` counterpart (but you have to install the [SciPy package](http://scipy.org/) for that). To print and compare PageRank values, you might want to use commands like `print('%.6f' % var)` to use regular decimal notation with a fixed number of decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:\n",
    "#pageranks = ...\n",
    "\n",
    "# print PageRank for paper 16869801\n",
    "# print PageRank for paper 21628697"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Why do the two papers above have such different PageRank values? Write code below to investigate and show the cause of this, and then explain the cause of this difference based on the results generated by your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** [_Write your answer text here_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Copy the scoring function `score_ntn` from Task 4 of assignment 3. Rename it to `score_ntn_pagerank` and change its code to incorporate a paper's PageRank score in it's final score, in addition to tf-idf. In other words, the new function should accept a `list` of query tokens and a document ID, and should return a single `float` value that is calculated based on both scores (PageRank and tf-idf). Note that a `tf-idf` function is already provided above. Explain your decision on how to combine the two scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** [_Write your answer text here_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Copy the query function `query_ntn` from Task 4 of assignment 3. Rename it to `query_ntn_pagerank` and change the code to use our new scoring function `score_ntn_pagerank` from task 4 above. Demonstrate these functions with an example query that returns our paper 16869801 from above as the top result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
