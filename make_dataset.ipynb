{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset of research papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) module, a part of the [Biopython](http://biopython.org/) library, will be used to interface with [PubMed](http://www.ncbi.nlm.nih.gov/pubmed).<br>\n",
    "You can download Biopython from [here](http://biopython.org/wiki/Download).\n",
    "\n",
    "In this notebook we will be covering several of the steps taken in the [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html), specifically in [Chapter 9  Accessing NCBI’s Entrez databases](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "# NCBI requires you to set your email address to make use of NCBI's E-utilities\n",
    "Entrez.email = \"Your.Name.Here@example.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets will be saved as serialized Python objects, compressed with bzip2.\n",
    "Saving/loading them will therefore require the [pickle](http://docs.python.org/3/library/pickle.html) and [bz2](http://docs.python.org/3/library/bz2.html) modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EInfo: Obtaining information about the Entrez databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing extended information about the PubMed database\n",
    "pubmed = Entrez.read( Entrez.einfo(db=\"pubmed\"), validate=False )[u'DbInfo']\n",
    "\n",
    "# list of possible search fields for use with ESearch:\n",
    "search_fields = { f['Name']:f['Description'] for f in pubmed[\"FieldList\"] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In search_fields, we find 'TIAB' ('Free text associated with Abstract/Title') as a possible search field to use in searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFFL': \"Author's institutional affiliation and address\",\n",
       " 'ALL': 'All terms from all searchable fields',\n",
       " 'AUCL': 'Author Cluster ID',\n",
       " 'AUID': 'Author Identifier',\n",
       " 'AUTH': 'Author(s) of publication',\n",
       " 'BOOK': 'ID of the book that contains the document',\n",
       " 'CDAT': 'Date of completion',\n",
       " 'CNTY': 'Country of publication',\n",
       " 'COIS': 'Conflict of Interest Statements',\n",
       " 'COLN': 'Corporate Author of publication',\n",
       " 'CRDT': 'Date publication first accessible through Entrez',\n",
       " 'DSO': 'Additional text from the summary',\n",
       " 'ECNO': 'EC number for enzyme or CAS registry number',\n",
       " 'ED': \"Section's Editor\",\n",
       " 'EDAT': 'Date publication first accessible through Entrez',\n",
       " 'EID': 'Extended PMID',\n",
       " 'EPDT': 'Date of Electronic publication',\n",
       " 'FAUT': 'First Author of publication',\n",
       " 'FILT': 'Limits the records',\n",
       " 'FINV': 'Full name of investigator',\n",
       " 'FULL': 'Full Author Name(s) of publication',\n",
       " 'GRNT': 'NIH Grant Numbers',\n",
       " 'INVR': 'Investigator',\n",
       " 'ISBN': 'ISBN',\n",
       " 'ISS': 'Issue number of publication',\n",
       " 'JOUR': 'Journal abbreviation of publication',\n",
       " 'LANG': 'Language of publication',\n",
       " 'LAUT': 'Last Author of publication',\n",
       " 'LID': 'ELocation ID',\n",
       " 'MAJR': 'MeSH terms of major importance to publication',\n",
       " 'MDAT': 'Date of last modification',\n",
       " 'MESH': 'Medical Subject Headings assigned to publication',\n",
       " 'MHDA': 'Date publication was indexed with MeSH terms',\n",
       " 'OTRM': 'Other terms associated with publication',\n",
       " 'PAGE': 'Page number(s) of publication',\n",
       " 'PAPX': 'MeSH pharmacological action pre-explosions',\n",
       " 'PDAT': 'Date of publication',\n",
       " 'PID': 'Publisher ID',\n",
       " 'PPDT': 'Date of print publication',\n",
       " 'PS': 'Personal Name as Subject',\n",
       " 'PTYP': 'Type of publication (e.g., review)',\n",
       " 'PUBN': \"Publisher's name\",\n",
       " 'SI': 'Cross-reference from publication to other databases',\n",
       " 'SUBH': 'Additional specificity for MeSH term',\n",
       " 'SUBS': 'CAS chemical name or MEDLINE Substance Name',\n",
       " 'TIAB': 'Free text associated with Abstract/Title',\n",
       " 'TITL': 'Words in title of publication',\n",
       " 'TT': 'Words in transliterated title of publication',\n",
       " 'UID': 'Unique number assigned to publication',\n",
       " 'VOL': 'Volume number of publication',\n",
       " 'WORD': 'Free text associated with publication'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESearch: Searching the Entrez databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the kind of data we get when searching the database, we'll perform a search for papers authored by Haasdijk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Count': '36', 'RetMax': '20', 'RetStart': '0', 'IdList': ['29311830', '28513205', '28513201', '28323435', '28140628', '26933487', '24977986', '24901702', '24852945', '24708899', '24252306', '23580075', '23144668', '22174697', '22154920', '21870131', '21760539', '20662596', '20602234', '20386726'], 'TranslationSet': [], 'TranslationStack': [{'Term': 'Haasdijk E[Author]', 'Field': 'Author', 'Count': '36', 'Explode': 'N'}, 'GROUP'], 'QueryTranslation': 'Haasdijk E[Author]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_authors = ['Haasdijk E']\n",
    "example_search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=' AND '.join([a+'[AUTH]' for a in example_authors]) ) )\n",
    "example_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the result being produced is not in Python's native string format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Entrez.Parser.StringElement"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( example_search['IdList'][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part of the query's result we are most interested in is accessible through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29311830, 28513205, 28513201, 28323435, 28140628, 26933487, 24977986, 24901702, 24852945, 24708899, 24252306, 23580075, 23144668, 22174697, 22154920, 21870131, 21760539, 20662596, 20602234, 20386726]\n"
     ]
    }
   ],
   "source": [
    "example_ids = [ int(id) for id in example_search['IdList'] ]\n",
    "print(example_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed IDs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now assemble a dataset comprised of research articles containing the given keyword, in either their titles or abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids_file = 'data/' + search_term + '__Ids.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82791 documents contain the search term \"tree\".\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists( Ids_file ):\n",
    "    Ids = pickle.load( bz2.BZ2File( Ids_file, 'rb' ) )\n",
    "else:\n",
    "    # determine the number of hits for the search term\n",
    "    search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retmax=0 ) )\n",
    "    total = int( search['Count'] )\n",
    "    \n",
    "    # `Ids` will be incrementally assembled, by performing multiple queries,\n",
    "    # each returning at most `retrieve_per_query` entries.\n",
    "    Ids_str = []\n",
    "    retrieve_per_query = 10000\n",
    "    \n",
    "    for start in range( 0, total, retrieve_per_query ):\n",
    "        print('Fetching IDs of results [%d,%d]' % ( start, start+retrieve_per_query ) )\n",
    "        s = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retstart=start, retmax=retrieve_per_query ) )\n",
    "        Ids_str.extend( s[ u'IdList' ] )\n",
    "    \n",
    "    # convert Ids to integers (and ensure that the conversion is reversible)\n",
    "    Ids = [ int(id) for id in Ids_str ]\n",
    "    \n",
    "    for (id_str, id_int) in zip(Ids_str, Ids):\n",
    "        if str(id_int) != id_str:\n",
    "            raise Exception('Conversion of PubMed ID %s from string to integer it not reversible.' % id_str )\n",
    "    \n",
    "    # Remove IDs that would cause problems below:\n",
    "    Ids.remove(28225291)\n",
    "    Ids.remove(26782917)\n",
    "    Ids.remove(25590543)\n",
    "    Ids.remove(25514435)\n",
    "    \n",
    "    # Save list of Ids\n",
    "    pickle.dump( Ids, bz2.BZ2File( Ids_file, 'wb' ) )\n",
    "    \n",
    "total = len( Ids )\n",
    "print('%d documents contain the search term \"%s\".' % ( total, search_term ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at what we just retrieved, here are the last 5 elements of the `Ids` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30227210, 30226902, 30226875, 30226423, 30226333]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESummary: Retrieving summaries from primary IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the kind of metadata we get from a call to `Entrez.esummary()`, we now fetch the summary of one of Haasdijk's papers (using one of the PubMed IDs we obtained in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item\n",
      "\t []\n",
      "Id\n",
      "\t 30227210\n",
      "PubDate\n",
      "\t 2018 Sep 15\n",
      "EPubDate\n",
      "\t 2018 Sep 15\n",
      "Source\n",
      "\t Int J Biol Macromol\n",
      "AuthorList\n",
      "\t ['Li Q', 'Wang Q', 'Jin X', 'Chen Z', 'Xiong C', 'Li P', 'Zhao J', 'Huang W']\n",
      "LastAuthor\n",
      "\t Huang W\n",
      "Title\n",
      "\t The first complete mitochondrial genome from the family Hygrophoraceae (Hygrophorus russula) by next-generation sequencing and phylogenetic implications.\n",
      "Volume\n",
      "\t \n",
      "Issue\n",
      "\t \n",
      "Pages\n",
      "\t \n",
      "LangList\n",
      "\t ['English']\n",
      "NlmUniqueID\n",
      "\t 7909578\n",
      "ISSN\n",
      "\t 0141-8130\n",
      "ESSN\n",
      "\t 1879-0003\n",
      "PubTypeList\n",
      "\t ['Journal Article']\n",
      "RecordStatus\n",
      "\t PubMed - as supplied by publisher\n",
      "PubStatus\n",
      "\t aheadofprint\n",
      "ArticleIds\n",
      "\t {'pubmed': ['30227210'], 'medline': [], 'pii': 'S0141-8130(18)34352-6', 'doi': '10.1016/j.ijbiomac.2018.09.091', 'rid': '30227210', 'eid': '30227210'}\n",
      "DOI\n",
      "\t 10.1016/j.ijbiomac.2018.09.091\n",
      "History\n",
      "\t {'pubmed': ['2018/09/19 06:00'], 'medline': ['2018/09/19 06:00'], 'received': '2018/08/18 00:00', 'revised': '2018/09/13 00:00', 'accepted': '2018/09/14 00:00', 'entrez': '2018/09/19 06:00'}\n",
      "References\n",
      "\t []\n",
      "HasAbstract\n",
      "\t 1\n",
      "PmcRefCount\n",
      "\t 0\n",
      "FullJournalName\n",
      "\t International journal of biological macromolecules\n",
      "ELocationID\n",
      "\t pii: S0141-8130(18)34352-6. doi: 10.1016/j.ijbiomac.2018.09.091\n",
      "SO\n",
      "\t 2018 Sep 15;\n"
     ]
    }
   ],
   "source": [
    "example_paper = Entrez.read( Entrez.esummary(db=\"pubmed\", id='30227210') )[0]\n",
    "\n",
    "def print_dict( p ):\n",
    "    for k,v in p.items():\n",
    "        print(k)\n",
    "        print('\\t', v)\n",
    "\n",
    "print_dict(example_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll keep just some basic information for each paper: title, list of authors, publication year, and [DOI](https://en.wikipedia.org/wiki/Digital_object_identifier).\n",
    "\n",
    "In case you are not familiar with the DOI system, know that the paper above can be accessed through the link  `https://www.doi.org/` followed by the paper's DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The first complete mitochondrial genome from the family Hygrophoraceae (Hygrophorus russula) by next-generation sequencing and phylogenetic implications.',\n",
       " ['Li Q', 'Wang Q', 'Jin X', 'Chen Z', 'Xiong C', 'Li P', 'Zhao J', 'Huang W'],\n",
       " 2018,\n",
       " '10.1016/j.ijbiomac.2018.09.091')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( example_paper['Title'], example_paper['AuthorList'], int(example_paper['PubDate'][:4]), example_paper['DOI'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to assemble a dataset containing the summaries of all the paper `Ids` we previously fetched.\n",
    "\n",
    "To reduce the memory footprint, and to ensure the saved datasets won't depend on Biopython being installed to be properly loaded, values returned by `Entrez.read()` will be converted to their corresponding native Python types. We start by defining a function for helping with the conversion of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summaries_file = 'data/' + search_term + '__Summaries.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists( Summaries_file ):\n",
    "    Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "else:\n",
    "    # `Summaries` will be incrementally assembled, by performing multiple queries,\n",
    "    # each returning at most `retrieve_per_query` entries.\n",
    "    Summaries = []\n",
    "    retrieve_per_query = 500\n",
    "    \n",
    "    print('Fetching Summaries of results: ')\n",
    "    for start in range( 0, len(Ids), retrieve_per_query ):\n",
    "        if (start % 10000 == 0):\n",
    "            print('')\n",
    "            print(start, end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        \n",
    "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
    "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
    "        \n",
    "        s = Entrez.read( Entrez.esummary( db=\"pubmed\", id=query_ids ) )\n",
    "        \n",
    "        # out of the retrieved data, we will keep only a tuple (title, authors, year, DOI), associated with the paper's id.\n",
    "        # (all values converted to native Python formats)\n",
    "        for p in s:\n",
    "            try:\n",
    "                f = [\n",
    "                    ( int( p['Id'] ), (\n",
    "                        str( p['Title'] ),\n",
    "                        [ str(a) for a in p['AuthorList'] ],\n",
    "                        int( p['PubDate'][:4] ),                # keeps just the publication year\n",
    "                        str( p.get('DOI', '') )            # papers for which no DOI is available get an empty string in their place\n",
    "                        ) )\n",
    "                    ]\n",
    "                Summaries.extend( f )\n",
    "            except ValueError as e:\n",
    "                print(\"\\nError with ID \" + p['Id'] + \": \" + str(e))\n",
    "                print(\"Manually remove this ID above and re-run code.\")\n",
    "    \n",
    "    # Save Summaries, as a dictionary indexed by Ids\n",
    "    Summaries = dict( Summaries )\n",
    "    \n",
    "    pickle.dump( Summaries, bz2.BZ2File( Summaries_file, 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the first 3 retrieved summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30226875: ('Digitizing extant bat diversity: An open-access repository of 3D μCT-scanned skulls for research and education.',\n",
       "  ['Shi JJ', 'Westeen EP', 'Rabosky DL'],\n",
       "  2018,\n",
       "  '10.1371/journal.pone.0203022'),\n",
       " 30226902: ('Tree species richness predicted using a spatial environmental model including forest area and frost frequency, eastern USA.',\n",
       "  ['Kwon Y', 'Larsen CPS', 'Lee M'],\n",
       "  2018,\n",
       "  '10.1371/journal.pone.0203881'),\n",
       " 30227210: ('The first complete mitochondrial genome from the family Hygrophoraceae (Hygrophorus russula) by next-generation sequencing and phylogenetic implications.',\n",
       "  ['Li Q',\n",
       "   'Wang Q',\n",
       "   'Jin X',\n",
       "   'Chen Z',\n",
       "   'Xiong C',\n",
       "   'Li P',\n",
       "   'Zhao J',\n",
       "   'Huang W'],\n",
       "  2018,\n",
       "  '10.1016/j.ijbiomac.2018.09.091')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ id : Summaries[id] for id in Ids[:3] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EFetch: Downloading full records from Entrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Entrez.efetch()` is the function that will allow us to obtain paper abstracts. Let us start by taking a look at the kind of data it returns when we query PubMed's database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Entrez.read( Entrez.efetch(db=\"pubmed\", id='30227210', retmode=\"xml\") )['PubmedArticle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`q` is a list, with each member corresponding to a queried id. Because here we only queried for one id, its results are then in `q[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q), len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\n",
    "At `q[0]` we find a dictionary containing two keys, the contents of which we print below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bio.Entrez.Parser.DictionaryElement,\n",
       " dict_keys(['MedlineCitation', 'PubmedData']))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q[0]), q[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History\n",
      "\t [DictElement({'Year': '2018', 'Month': '08', 'Day': '18'}, attributes={'PubStatus': 'received'}), DictElement({'Year': '2018', 'Month': '09', 'Day': '13'}, attributes={'PubStatus': 'revised'}), DictElement({'Year': '2018', 'Month': '09', 'Day': '14'}, attributes={'PubStatus': 'accepted'}), DictElement({'Year': '2018', 'Month': '9', 'Day': '19', 'Hour': '6', 'Minute': '0'}, attributes={'PubStatus': 'entrez'}), DictElement({'Year': '2018', 'Month': '9', 'Day': '19', 'Hour': '6', 'Minute': '0'}, attributes={'PubStatus': 'pubmed'}), DictElement({'Year': '2018', 'Month': '9', 'Day': '19', 'Hour': '6', 'Minute': '0'}, attributes={'PubStatus': 'medline'})]\n",
      "PublicationStatus\n",
      "\t aheadofprint\n",
      "ArticleIdList\n",
      "\t [StringElement('30227210', attributes={'IdType': 'pubmed'}), StringElement('S0141-8130(18)34352-6', attributes={'IdType': 'pii'}), StringElement('10.1016/j.ijbiomac.2018.09.091', attributes={'IdType': 'doi'})]\n"
     ]
    }
   ],
   "source": [
    "print_dict( q[0][ 'PubmedData' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key `'MedlineCitation'` maps into another dictionary. In that dictionary, most of the information is contained under the key `'Article'`. To minimize the clutter, below we show the contents of `'MedlineCitation'` excluding its `'Article'` member, and below that we then show the contents of `'Article'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CitationSubset\n",
      "\t []\n",
      "OtherID\n",
      "\t []\n",
      "OtherAbstract\n",
      "\t []\n",
      "KeywordList\n",
      "\t [ListElement([StringElement('Gene rearrangement', attributes={'MajorTopicYN': 'N'}), StringElement('Hygrophorus', attributes={'MajorTopicYN': 'N'}), StringElement('Mitochondrial genome', attributes={'MajorTopicYN': 'N'}), StringElement('Phylogenetic analysis', attributes={'MajorTopicYN': 'N'}), StringElement('Protein-encoding gene', attributes={'MajorTopicYN': 'N'}), StringElement('Repeat sequence', attributes={'MajorTopicYN': 'N'})], attributes={'Owner': 'NOTNLM'})]\n",
      "SpaceFlightMission\n",
      "\t []\n",
      "GeneralNote\n",
      "\t []\n",
      "PMID\n",
      "\t 30227210\n",
      "DateRevised\n",
      "\t {'Year': '2018', 'Month': '09', 'Day': '18'}\n",
      "MedlineJournalInfo\n",
      "\t {'Country': 'Netherlands', 'MedlineTA': 'Int J Biol Macromol', 'NlmUniqueID': '7909578', 'ISSNLinking': '0141-8130'}\n"
     ]
    }
   ],
   "source": [
    "print_dict( { k:v for k,v in q[0][ 'MedlineCitation' ].items() if k!='Article' } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELocationID\n",
      "\t [StringElement('S0141-8130(18)34352-6', attributes={'EIdType': 'pii', 'ValidYN': 'Y'}), StringElement('10.1016/j.ijbiomac.2018.09.091', attributes={'EIdType': 'doi', 'ValidYN': 'Y'})]\n",
      "Language\n",
      "\t ['eng']\n",
      "ArticleDate\n",
      "\t [DictElement({'Year': '2018', 'Month': '09', 'Day': '15'}, attributes={'DateType': 'Electronic'})]\n",
      "Journal\n",
      "\t {'ISSN': StringElement('1879-0003', attributes={'IssnType': 'Electronic'}), 'JournalIssue': DictElement({'PubDate': {'Year': '2018', 'Month': 'Sep', 'Day': '15'}}, attributes={'CitedMedium': 'Internet'}), 'Title': 'International journal of biological macromolecules', 'ISOAbbreviation': 'Int. J. Biol. Macromol.'}\n",
      "ArticleTitle\n",
      "\t The first complete mitochondrial genome from the family Hygrophoraceae (Hygrophorus russula) by next-generation sequencing and phylogenetic implications.\n",
      "Abstract\n",
      "\t {'AbstractText': ['Hygrophorus russula (Schaeff.) Kauffman is an edible ectomycorrhizal fungus that is widely distributed in the world. In this study, the mitogenome of H. russula was sequenced and assembled. The mitogenome of H. russula is composed of circular DNA molecules, with a total size of 55,769\\u202fbp. Further analysis indicated that the frequent use of A and T in codons contributes to the high AT content (80.87%) in the H. russula mitogenome. Comparative analysis indicated that the length and base composition of the core protein-encoding genes, and the number of tRNA genes in the H. russula mitogenome varied from that of other Agaricales mitogenomes. Gene arrangement analysis revealed a novel gene order in the H. russula mitogenome. In addition, the expansion of the mitogenome in Agaricales was found to be closely related to the increase in the number of introns. Phylogenetic analysis of the combined mitochondrial gene set showed strong support for tree topologies, and H. russula was determined to be relatively distant from other Agaricales species. This study is the first report on the mitogenome of a member of genus Hygrophorus as well as family Hygrophoraceae, which improves our understanding of mitochondrial differentiation and evolution in the important ectomycorrhizal fungi Hygrophorus species.'], 'CopyrightInformation': 'Copyright © 2018. Published by Elsevier B.V.'}\n",
      "AuthorList\n",
      "\t ListElement([DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China; Key Laboratory of Bio-Resource and Eco-Environment of Ministry of Education, College of Life Sciences, Sichuan University, Chengdu 610065, Sichuan, PR China.'}], 'LastName': 'Li', 'ForeName': 'Qiang', 'Initials': 'Q'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China.'}], 'LastName': 'Wang', 'ForeName': 'Qiangfeng', 'Initials': 'Q'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China.'}], 'LastName': 'Jin', 'ForeName': 'Xin', 'Initials': 'X'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China.'}], 'LastName': 'Chen', 'ForeName': 'Zuqin', 'Initials': 'Z'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China.'}], 'LastName': 'Xiong', 'ForeName': 'Chuan', 'Initials': 'C'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China.'}], 'LastName': 'Li', 'ForeName': 'Ping', 'Initials': 'P'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Key Laboratory of Bio-Resource and Eco-Environment of Ministry of Education, College of Life Sciences, Sichuan University, Chengdu 610065, Sichuan, PR China. Electronic address: zj804@163.com.'}], 'LastName': 'Zhao', 'ForeName': 'Jian', 'Initials': 'J'}, attributes={'ValidYN': 'Y'}), DictElement({'Identifier': [], 'AffiliationInfo': [{'Identifier': [], 'Affiliation': 'Biotechnology and Nuclear Technology Research Institute, Sichuan Academy of Agricultural Sciences, Chengdu 610061, Sichuan, PR China. Electronic address: wenlih11@126.com.'}], 'LastName': 'Huang', 'ForeName': 'Wenli', 'Initials': 'W'}, attributes={'ValidYN': 'Y'})], attributes={'CompleteYN': 'Y'})\n",
      "PublicationTypeList\n",
      "\t [StringElement('Journal Article', attributes={'UI': 'D016428'})]\n"
     ]
    }
   ],
   "source": [
    "print_dict( q[0][ 'MedlineCitation' ][ 'Article' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paper's abstract can therefore be accessed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30227210: 'Hygrophorus russula (Schaeff.) Kauffman is an edible ectomycorrhizal fungus that is widely distributed in the world. In this study, the mitogenome of H. russula was sequenced and assembled. The mitogenome of H. russula is composed of circular DNA molecules, with a total size of 55,769\\u202fbp. Further analysis indicated that the frequent use of A and T in codons contributes to the high AT content (80.87%) in the H. russula mitogenome. Comparative analysis indicated that the length and base composition of the core protein-encoding genes, and the number of tRNA genes in the H. russula mitogenome varied from that of other Agaricales mitogenomes. Gene arrangement analysis revealed a novel gene order in the H. russula mitogenome. In addition, the expansion of the mitogenome in Agaricales was found to be closely related to the increase in the number of introns. Phylogenetic analysis of the combined mitochondrial gene set showed strong support for tree topologies, and H. russula was determined to be relatively distant from other Agaricales species. This study is the first report on the mitogenome of a member of genus Hygrophorus as well as family Hygrophoraceae, which improves our understanding of mitochondrial differentiation and evolution in the important ectomycorrhizal fungi Hygrophorus species.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ int(q[0]['MedlineCitation']['PMID']) : str(q[0]['MedlineCitation']['Article']['Abstract']['AbstractText'][0]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the ids in our dataset refer to books from the [NCBI Bookshelf](http://www.ncbi.nlm.nih.gov/books/), a collection of freely available, downloadable, on-line versions of selected biomedical books. For such ids, `Entrez.efetch()` returns a slightly different structure, where the keys `[u'BookDocument', u'PubmedBookData']` take the place of the `[u'MedlineCitation', u'PubmedData']` keys we saw above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assemble a dataset mapping paper ids to their abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstracts_file = 'data/' + search_term + '__Abstracts.pkl.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Abstracts of results: \n",
      "\n",
      "0...................\n",
      "10000...................\n",
      "20000...................\n",
      "30000...................\n",
      "40000...................\n",
      "50000...................\n",
      "60000...................\n",
      "70000...................\n",
      "80000....."
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "from collections import deque\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "\n",
    "def ch(node, childtype):\n",
    "    return node.getElementsByTagName(childtype)[0]\n",
    "\n",
    "if os.path.exists( Abstracts_file ):\n",
    "    Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "else:\n",
    "    # `Abstracts` will be incrementally assembled, by performing multiple queries,\n",
    "    # each returning at most `retrieve_per_query` entries.\n",
    "    Abstracts = deque()\n",
    "    retrieve_per_query = 500\n",
    "    \n",
    "    print('Fetching Abstracts of results: ')\n",
    "    for start in range( 0, len(Ids), retrieve_per_query ):\n",
    "        if (start % 10000 == 0):\n",
    "            print('')\n",
    "            print(start, end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        \n",
    "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
    "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
    "        \n",
    "        # issue requests to the server, until we get the full amount of data we expect\n",
    "        while True:\n",
    "            try:\n",
    "                #s = Entrez.read( Entrez.efetch(db=\"pubmed\", id=query_ids, retmode=\"xml\" ) )['PubmedArticle']\n",
    "                s = minidom.parse( Entrez.efetch(db=\"pubmed\", id=query_ids, retmode=\"xml\" ) ).getElementsByTagName(\"PubmedArticle\")\n",
    "            except http.client.IncompleteRead:\n",
    "                print('r', end='')\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        i = 0\n",
    "        for p in s:\n",
    "            abstr = ''\n",
    "            if (p.getElementsByTagName('MedlineCitation')):\n",
    "                citNode = ch(p,'MedlineCitation')\n",
    "                pmid = ch(citNode,'PMID').firstChild.data\n",
    "                articleNode = ch(citNode,'Article')\n",
    "                if (articleNode.getElementsByTagName('Abstract')):\n",
    "                    try:\n",
    "                        abstr = ch(ch(articleNode,'Abstract'),'AbstractText').firstChild.data\n",
    "                    except AttributeError:\n",
    "                        abstr = ch(ch(articleNode,'Abstract'),'AbstractText').toprettyxml(\"  \")\n",
    "                        abstr = re.sub(r\"\\s+\", \" \", re.sub(\"<[^>]*>\", \"\", abstr))\n",
    "            elif (p.getElementsByTagName('BookDocument')):\n",
    "                bookNode = ch(p,'BookDocument')\n",
    "                pmid = ch(bookNode,'PMID').firstChild.data\n",
    "                if (bookNode.getElementsByTagName('Abstract')):\n",
    "                    try:\n",
    "                        abstr = ch(ch(bookNode,'Abstract'),'AbstractText').firstChild.data\n",
    "                    except AttributeError:\n",
    "                        abstr = ch(ch(bookNode,'Abstract'),'AbstractText').toprettyxml(\"  \")\n",
    "                        abstr = re.sub(r\"\\s+\", \" \", re.sub(\"<[^>]*>\", \"\", abstr))\n",
    "            else:\n",
    "                raise Exception('Unrecognized record type, for id %d (keys: %s)' % (Ids[start+i], str(p.keys())) )\n",
    "            \n",
    "            Abstracts.append( (int(pmid), str(abstr)) )\n",
    "            i += 1\n",
    "    \n",
    "    # Save Abstracts, as a dictionary indexed by Ids\n",
    "    Abstracts = dict( Abstracts )\n",
    "    \n",
    "    pickle.dump( Abstracts, bz2.BZ2File( Abstracts_file, 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at one paper's abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hygrophorus russula (Schaeff.) Kauffman is an edible ectomycorrhizal fungus that is widely distributed in the world. In this study, the mitogenome of H. russula was sequenced and assembled. The mitogenome of H. russula is composed of circular DNA molecules, with a total size of 55,769\\u202fbp. Further analysis indicated that the frequent use of A and T in codons contributes to the high AT content (80.87%) in the H. russula mitogenome. Comparative analysis indicated that the length and base composition of the core protein-encoding genes, and the number of tRNA genes in the H. russula mitogenome varied from that of other Agaricales mitogenomes. Gene arrangement analysis revealed a novel gene order in the H. russula mitogenome. In addition, the expansion of the mitogenome in Agaricales was found to be closely related to the increase in the number of introns. Phylogenetic analysis of the combined mitochondrial gene set showed strong support for tree topologies, and H. russula was determined to be relatively distant from other Agaricales species. This study is the first report on the mitogenome of a member of genus Hygrophorus as well as family Hygrophoraceae, which improves our understanding of mitochondrial differentiation and evolution in the important ectomycorrhizal fungi Hygrophorus species.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abstracts[30227210]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELink: Searching for related items in NCBI Entrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to obtain paper citations with Entrez, we will first assemble a small set of PubMed IDs, and then query for their citations.\n",
    "To that end, we search here for papers published in the Nature journal with our given keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30209378', '30185910', '30089906', '30089903', '30061647', '29950621', '29805161', '29743673', '29720652', '29643510', '29595767', '29562235', '29513656', '29446396', '29420476', '29364285', '29298288', '29211724', '29094688', '29052630']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_search_term = search_term+'[TIAB] AND Nature[JOUR]'\n",
    "CA_ids = Entrez.read( Entrez.esearch( db=\"pubmed\", term=CA_search_term ) )['IdList']\n",
    "CA_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'29052630': ('Mastering the game of Go without human knowledge.',\n",
       "  ['Silver D', 'Schrittwieser J', 'Simonyan K', 'Antonoglou I', 'Huang A', 'Guez A', 'Hubert T', 'Baker L', 'Lai M', 'Bolton A', 'Chen Y', 'Lillicrap T', 'Hui F', 'Sifre L', 'van den Driessche G', 'Graepel T', 'Hassabis D'],\n",
       "  '2017',\n",
       "  'Nature',\n",
       "  '10.1038/nature24270'),\n",
       " '29094688': ('Untangling the dinosaur family tree.',\n",
       "  ['Langer MC', 'Ezcurra MD', 'Rauhut OWM', 'Benton MJ', 'Knoll F', 'McPhee BW', 'Novas FE', 'Pol D', 'Brusatte SL'],\n",
       "  '2017',\n",
       "  'Nature',\n",
       "  '10.1038/nature24011'),\n",
       " '29211724': ('Large emissions from floodplain trees close the Amazon methane budget.',\n",
       "  ['Pangala SR', 'Enrich-Prast A', 'Basso LS', 'Peixoto RB', 'Bastviken D', 'Hornibrook ERC', 'Gatti LV', 'Marotta H', 'Calazans LSB', 'Sakuragui CM', 'Bastos WR', 'Malm O', 'Gloor E', 'Miller JB', 'Gauci V'],\n",
       "  '2017',\n",
       "  'Nature',\n",
       "  '10.1038/nature24639'),\n",
       " '29298288': ('Hierarchically related lineage-restricted fates of multipotent haematopoietic stem cells.',\n",
       "  ['Carrelha J', 'Meng Y', 'Kettyle LM', 'Luis TC', 'Norfo R', 'Alcolea V', 'Boukarabila H', 'Grasso F', 'Gambardella A', 'Grover A', 'Högstrand K', 'Lord AM', 'Sanjuan-Pla A', 'Woll PS', 'Nerlov C', 'Jacobsen SEW'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/nature25455'),\n",
       " '29364285': ('From haematopoietic stem cells to complex differentiation landscapes.',\n",
       "  ['Laurenti E', 'Göttgens B'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/nature25022'),\n",
       " '29420476': ('Evolutionary history of the angiosperm flora of China.',\n",
       "  ['Lu LM', 'Mao LF', 'Yang T', 'Ye JF', 'Liu B', 'Li HL', 'Sun M', 'Miller JT', 'Mathews S', 'Hu HH', 'Niu YT', 'Peng DX', 'Chen YH', 'Smith SA', 'Chen M', 'Xiang KL', 'Le CT', 'Dang VC', 'Lu AM', 'Soltis PS', 'Soltis DE', 'Li JH', 'Chen ZD'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/nature25485'),\n",
       " '29446396': ('Tree rings reveal increased fire risk for southwestern US.',\n",
       "  ['Carswell C'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/d41586-018-01686-y'),\n",
       " '29513656': ('Pervasive phosphorus limitation of tree species but not communities in tropical forests.',\n",
       "  ['Turner BL', 'Brenes-Arguedas T', 'Condit R'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/nature25789'),\n",
       " '29562235': ('Shifts in tree functional composition amplify the response of forest biomass to climate.',\n",
       "  ['Zhang T', 'Niinemets Ü', 'Sheffield J', 'Lichstein JW'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/nature26152'),\n",
       " '29595767': ('Planning chemical syntheses with deep neural networks and symbolic AI.',\n",
       "  ['Segler MHS', 'Preuss M', 'Waller MP'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/nature25978'),\n",
       " '29643510': ('Intra-tumour diversification in colorectal cancer at the single-cell level.',\n",
       "  ['Roerink SF', 'Sasaki N', 'Lee-Six H', 'Young MD', 'Alexandrov LB', 'Behjati S', 'Mitchell TJ', 'Grossmann S', 'Lightfoot H', 'Egan DA', 'Pronk A', 'Smakman N', 'van Gorp J', 'Anderson E', 'Gamble SJ', 'Alder C', 'van de Wetering M', 'Campbell PJ', 'Stratton MR', 'Clevers H'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0024-3'),\n",
       " '29720652': ('Publisher Correction: Pervasive phosphorus limitation of tree species but not communities in tropical forests.',\n",
       "  ['Turner BL', 'Brenes-Arguedas T', 'Condit R'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0099-x'),\n",
       " '29743673': ('Ancient hepatitis B viruses from the Bronze Age to the Medieval period.',\n",
       "  ['Mühlemann B', 'Jones TC', 'Damgaard PB', 'Allentoft ME', 'Shevnina I', 'Logvin A', 'Usmanova E', 'Panyushkina IP', 'Boldgiv B', 'Bazartseren T', 'Tashbaeva K', 'Merz V', 'Lau N', 'Smrčka V', 'Voyakin D', 'Kitov E', 'Epimakhov A', 'Pokutta D', 'Vicze M', 'Price TD', 'Moiseyev V', 'Hansen AJ', 'Orlando L', 'Rasmussen S', 'Sikora M', 'Vinner L', 'Osterhaus ADME', 'Smith DJ', 'Glebe D', 'Fouchier RAM', 'Drosten C', 'Sjögren KG', 'Kristiansen K', 'Willerslev E'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0097-z'),\n",
       " '29805161': ('The giant rock that wiped out tree-dwelling birds.',\n",
       "  [],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/d41586-018-05228-4'),\n",
       " '29950621': ('Triggers of tree mortality under drought.',\n",
       "  ['Choat B', 'Brodribb TJ', 'Brodersen CR', 'Duursma RA', 'López R', 'Medlyn BE'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0240-x'),\n",
       " '30061647': ('The band of biologists who redrew the tree of life.',\n",
       "  ['Archibald J'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/d41586-018-05827-1'),\n",
       " '30089903': ('Global land change from 1982 to 2016.',\n",
       "  ['Song XP', 'Hansen MC', 'Stehman SV', 'Potapov PV', 'Tyukavina A', 'Vermote EF', 'Townshend JR'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0411-9'),\n",
       " '30089906': ('RNA velocity of single cells.',\n",
       "  ['La Manno G', 'Soldatov R', 'Zeisel A', 'Braun E', 'Hochgerner H', 'Petukhov V', 'Lidschreiber K', 'Kastriti ME', 'Lönnerberg P', 'Furlan A', 'Fan J', 'Borm LE', 'Liu Z', 'van Bruggen D', 'Guo J', 'He X', 'Barker R', 'Sundström E', 'Castelo-Branco G', 'Cramer P', 'Adameyko I', 'Linnarsson S', 'Kharchenko PV'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0414-6'),\n",
       " '30185910': ('Population dynamics of normal human blood inferred from somatic mutations.',\n",
       "  ['Lee-Six H', 'Øbro NF', 'Shepherd MS', 'Grossmann S', 'Dawson K', 'Belmonte M', 'Osborne RJ', 'Huntly BJP', 'Martincorena I', 'Anderson E', \"O'Neill L\", 'Stratton MR', 'Laurenti E', 'Green AR', 'Kent DG', 'Campbell PJ'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/s41586-018-0497-0'),\n",
       " '30209378': (\"Calling time on New Zealand's oldest tree species.\",\n",
       "  ['Black A', 'Waipara N', 'Gerth M'],\n",
       "  '2018',\n",
       "  'Nature',\n",
       "  '10.1038/d41586-018-06629-1')}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_summ = {\n",
    "    p['Id'] : ( p['Title'], p['AuthorList'], p['PubDate'][:4], p['FullJournalName'], p.get('DOI', '') )\n",
    "    for p in Entrez.read( Entrez.esummary(db=\"pubmed\", id=','.join( CA_ids )) )\n",
    "    }\n",
    "CA_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we restricted our search to papers in an open-access journal, you can then follow their DOIs to freely access their PDFs at the journal's website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now issue calls to `Entrez.elink()` using these PubMed IDs, to retrieve the IDs of papers that cite them.\n",
    "The database from which the IDs will be retrieved is [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/), a free digital database of full-text scientific literature in the biomedical and life sciences.\n",
    "\n",
    "A complete list of the kinds of links you can retrieve with `Entrez.elink()` can be found [here](http://eutils.ncbi.nlm.nih.gov/entrez/query/static/entrezlinks.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ERROR': [], 'LinkSetDb': [{'Link': [{'Id': '6132900'}, {'Id': '6120714'}, {'Id': '6107860'}, {'Id': '6103992'}, {'Id': '6081423'}, {'Id': '6052547'}, {'Id': '6052166'}, {'Id': '6048531'}, {'Id': '6029810'}, {'Id': '6028944'}, {'Id': '6028621'}, {'Id': '6002113'}, {'Id': '5982701'}, {'Id': '5966805'}, {'Id': '5945692'}, {'Id': '5865176'}, {'Id': '5863044'}, {'Id': '5821847'}, {'Id': '5770642'}, {'Id': '5716658'}], 'DbTo': 'pmc', 'LinkName': 'pubmed_pmc_refs'}], 'LinkSetDbHistory': [], 'DbFrom': 'pubmed', 'IdList': ['29052630']}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_citing = {\n",
    "    id : Entrez.read( Entrez.elink(\n",
    "            cmd = \"neighbor\",               # ELink command mode: \"neighbor\", returns\n",
    "                                            #     a set of UIDs in `db` linked to the input UIDs in `dbfrom`.\n",
    "            dbfrom = \"pubmed\",              # Database containing the input UIDs: PubMed\n",
    "            db = \"pmc\",                     # Database from which to retrieve UIDs: PubMed Central\n",
    "            LinkName = \"pubmed_pmc_refs\",   # Name of the Entrez link to retrieve: \"pubmed_pmc_refs\", gets\n",
    "                                            #     \"Full-text articles in the PubMed Central Database that cite the current articles\"\n",
    "            from_uid = id                   # input UIDs\n",
    "            ) )\n",
    "    for id in CA_ids\n",
    "    }\n",
    "\n",
    "CA_citing['29052630']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have in `CA_citing[paper_id][0]['LinkSetDb'][0]['Link']` the list of papers citing `paper_id`. To get it as just a list of ids, we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6132900',\n",
       " '6120714',\n",
       " '6107860',\n",
       " '6103992',\n",
       " '6081423',\n",
       " '6052547',\n",
       " '6052166',\n",
       " '6048531',\n",
       " '6029810',\n",
       " '6028944',\n",
       " '6028621',\n",
       " '6002113',\n",
       " '5982701',\n",
       " '5966805',\n",
       " '5945692',\n",
       " '5865176',\n",
       " '5863044',\n",
       " '5821847',\n",
       " '5770642',\n",
       " '5716658']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cits = [ l['Id'] for l in CA_citing['29052630'][0]['LinkSetDb'][0]['Link'] ]\n",
    "cits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, one more step is needed, as what we have now are PubMed Central IDs, and not PubMed IDs. Their conversion can be achieved through an additional call to `Entrez.elink()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ERROR': [], 'LinkSetDb': [{'Link': [{'Id': '30159387'}, {'Id': '30134902'}, {'Id': '30087331'}, {'Id': '30022085'}, {'Id': '30021530'}, {'Id': '30003314'}, {'Id': '29997493'}, {'Id': '29946023'}, {'Id': '29927936'}, {'Id': '29902180'}, {'Id': '29780633'}, {'Id': '29695066'}, {'Id': '29599739'}, {'Id': '29572466'}, {'Id': '29467373'}, {'Id': '29375355'}, {'Id': '29205152'}], 'DbTo': 'pubmed', 'LinkName': 'pmc_pubmed'}], 'LinkSetDbHistory': [], 'DbFrom': 'pmc', 'IdList': ['6132900', '6120714', '6107860', '6103992', '6081423', '6052547', '6052166', '6048531', '6029810', '6028944', '6028621', '6002113', '5982701', '5966805', '5945692', '5865176', '5863044', '5821847', '5770642', '5716658']}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cits_pm = Entrez.read( Entrez.elink( dbfrom=\"pmc\", db=\"pubmed\", LinkName=\"pmc_pubmed\", from_uid=\",\".join(cits)) )\n",
    "cits_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5863044': '29205152',\n",
       " '5865176': '29375355',\n",
       " '5945692': '29467373',\n",
       " '5966805': '29572466',\n",
       " '5982701': '29599739',\n",
       " '6002113': '29695066',\n",
       " '6028621': '29780633',\n",
       " '6028944': '29902180',\n",
       " '6029810': '29927936',\n",
       " '6048531': '29946023',\n",
       " '6052166': '29997493',\n",
       " '6052547': '30003314',\n",
       " '6081423': '30021530',\n",
       " '6103992': '30022085',\n",
       " '6107860': '30087331',\n",
       " '6120714': '30134902',\n",
       " '6132900': '30159387'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_map = { pmc_id : link['Id'] for (pmc_id,link) in zip(cits_pm[0]['IdList'], cits_pm[0]['LinkSetDb'][0]['Link']) }\n",
    "ids_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to check these papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'29205152': ('Branching into brains.',\n",
       "  ['Shai A', 'Larkum ME'],\n",
       "  '2017',\n",
       "  'eLife',\n",
       "  '10.7554/eLife.33066'),\n",
       " '29375355': ('Computational Foundations of Natural Intelligence.',\n",
       "  ['van Gerven M'],\n",
       "  '2017',\n",
       "  'Frontiers in computational neuroscience',\n",
       "  '10.3389/fncom.2017.00112'),\n",
       " '29467373': ('Deep learning based tissue analysis predicts outcome in colorectal cancer.',\n",
       "  ['Bychkov D', 'Linder N', 'Turkki R', 'Nordling S', 'Kovanen PE', 'Verrill C', 'Walliander M', 'Lundin M', 'Haglund C', 'Lundin J'],\n",
       "  '2018',\n",
       "  'Scientific reports',\n",
       "  '10.1038/s41598-018-21758-3'),\n",
       " '29572466': ('Adaptive nodes enrich nonlinear cooperative learning beyond traditional adaptation by links.',\n",
       "  ['Sardi S', 'Vardi R', 'Goldental A', 'Sheinin A', 'Uzan H', 'Kanter I'],\n",
       "  '2018',\n",
       "  'Scientific reports',\n",
       "  '10.1038/s41598-018-23471-7'),\n",
       " '29599739': ('Illusory Motion Reproduced by Deep Neural Networks Trained for Prediction.',\n",
       "  ['Watanabe E', 'Kitaoka A', 'Sakamoto K', 'Yasugi M', 'Tanaka K'],\n",
       "  '2018',\n",
       "  'Frontiers in psychology',\n",
       "  '10.3389/fpsyg.2018.00345'),\n",
       " '29695066': ('Learning Perfectly Secure Cryptography to Protect Communications with Adversarial Neural Cryptography.',\n",
       "  ['Coutinho M', 'de Oliveira Albuquerque R', 'Borges F', 'García Villalba LJ', 'Kim TH'],\n",
       "  '2018',\n",
       "  'Sensors (Basel, Switzerland)',\n",
       "  '10.3390/s18051306'),\n",
       " '29780633': ('Deep learning aided decision support for pulmonary nodules diagnosing: a review.',\n",
       "  ['Yang Y', 'Feng X', 'Chi W', 'Li Z', 'Duan W', 'Liu H', 'Liang W', 'Wang W', 'Chen P', 'He J', 'Liu B'],\n",
       "  '2018',\n",
       "  'Journal of thoracic disease',\n",
       "  '10.21037/jtd.2018.02.57'),\n",
       " '29902180': ('No free lunch in ball catching: A comparison of Cartesian and angular representations for control.',\n",
       "  ['Höfer S', 'Raisch J', 'Toussaint M', 'Brock O'],\n",
       "  '2018',\n",
       "  'PloS one',\n",
       "  '10.1371/journal.pone.0197803'),\n",
       " '29927936': ('Solving the RNA design problem with reinforcement learning.',\n",
       "  ['Eastman P', 'Shi J', 'Ramsundar B', 'Pande VS'],\n",
       "  '2018',\n",
       "  'PLoS computational biology',\n",
       "  '10.1371/journal.pcbi.1006176'),\n",
       " '29946023': ('Learning atoms for materials discovery.',\n",
       "  ['Zhou Q', 'Tang P', 'Liu S', 'Pan J', 'Yan Q', 'Zhang SC'],\n",
       "  '2018',\n",
       "  'Proceedings of the National Academy of Sciences of the United States of America',\n",
       "  '10.1073/pnas.1801181115'),\n",
       " '29997493': ('SERKET: An Architecture for Connecting Stochastic Models to Realize a Large-Scale Cognitive Model.',\n",
       "  ['Nakamura T', 'Nagai T', 'Taniguchi T'],\n",
       "  '2018',\n",
       "  'Frontiers in neurorobotics',\n",
       "  '10.3389/fnbot.2018.00025'),\n",
       " '30003314': ('Beyond playing games: nephrologist vs machine in pediatric dialysis prescribing.',\n",
       "  ['Hayes W', 'Allinovi M'],\n",
       "  '2018',\n",
       "  'Pediatric nephrology (Berlin, Germany)',\n",
       "  '10.1007/s00467-018-4021-4'),\n",
       " '30021530': ('De novo profile generation based on sequence context specificity with the long short-term memory network.',\n",
       "  ['Yamada KD', 'Kinoshita K'],\n",
       "  '2018',\n",
       "  'BMC bioinformatics',\n",
       "  '10.1186/s12859-018-2284-1'),\n",
       " '30022085': ('Scalable photonic reinforcement learning by time-division multiplexing of laser chaos.',\n",
       "  ['Naruse M', 'Mihana T', 'Hori H', 'Saigo H', 'Okamura K', 'Hasegawa M', 'Uchida A'],\n",
       "  '2018',\n",
       "  'Scientific reports',\n",
       "  '10.1038/s41598-018-29117-y'),\n",
       " '30087331': ('Deep learning to predict the lab-of-origin of engineered DNA.',\n",
       "  ['Nielsen AAK', 'Voigt CA'],\n",
       "  '2018',\n",
       "  'Nature communications',\n",
       "  '10.1038/s41467-018-05378-z'),\n",
       " '30134902': ('Computer-aided detection in chest radiography based on artificial intelligence: a survey.',\n",
       "  ['Qin C', 'Yao D', 'Shi Y', 'Song Z'],\n",
       "  '2018',\n",
       "  'Biomedical engineering online',\n",
       "  '10.1186/s12938-018-0544-y'),\n",
       " '30159387': ('ACS Central Science Virtual Issue on Machine Learning.',\n",
       "  ['Ferguson AL'],\n",
       "  '2018',\n",
       "  'ACS central science',\n",
       "  '10.1021/acscentsci.8b00528')}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{   p['Id'] : ( p['Title'], p['AuthorList'], p['PubDate'][:4], p['FullJournalName'], p.get('DOI', '') )\n",
    "    for p in Entrez.read( Entrez.esummary(db=\"pubmed\", id=','.join( ids_map.values() )) )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now seen all the steps required to assemble a dataset of citations to each of the papers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citations_file = 'data/' + search_term + '__Citations.pkl.bz2'\n",
    "Citations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least one server query will be issued per paper in `Ids`. Because NCBI allows for at most 3 queries per second (see [here](http://biopython.org/DIST/docs/api/Bio.Entrez-pysrc.html#_open)), this dataset will take a long time to assemble. Should you need to interrupt it for some reason, or the connection fail at some point, it is safe to just rerun the cell below until all data is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................\n",
      "20000........................"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-56cf24bada87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# query for papers archived in PubMed Central that cite the paper with PubMed ID `pm_id`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melink\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdbfrom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pubmed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pmc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinkName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pubmed_pmc_refs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LinkSetDb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/Bio/Entrez/__init__.py\u001b[0m in \u001b[0;36melink\u001b[0;34m(**keywds)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/Bio/Entrez/__init__.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(cgi, params, post, ecitmatch)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_as_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_HTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1361\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\\r\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1400\u001b[0;31m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[1;32m   1401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    405\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                          _context=self, _session=session)\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     def wrap_bio(self, incoming, outgoing, server_side=False,\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)\u001b[0m\n\u001b[1;32m    812\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "\n",
    "if Citations == [] and os.path.exists( Citations_file ):\n",
    "    Citations = pickle.load( bz2.BZ2File( Citations_file, 'rb' ) )\n",
    "\n",
    "if len(Citations) < len(Ids):\n",
    "    \n",
    "    i = len(Citations)\n",
    "    checkpoint = len(Ids) / 10 + 1      # save to hard drive at every 10% of Ids fetched\n",
    "    \n",
    "    for pm_id in Ids[i:]:               # either starts from index 0, or resumes from where we previously left off\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # query for papers archived in PubMed Central that cite the paper with PubMed ID `pm_id`\n",
    "                c = Entrez.read( Entrez.elink( dbfrom = \"pubmed\", db=\"pmc\", LinkName = \"pubmed_pmc_refs\", id=str(pm_id) ) )\n",
    "                \n",
    "                c = c[0]['LinkSetDb']\n",
    "                if len(c) == 0:\n",
    "                    # no citations found for the current paper\n",
    "                    c = []\n",
    "                else:\n",
    "                    c = [ l['Id'] for l in c[0]['Link'] ]\n",
    "                    \n",
    "                    # convert citations from PubMed Central IDs to PubMed IDs\n",
    "                    p = []\n",
    "                    retrieve_per_query = 500\n",
    "                    for start in range( 0, len(c), retrieve_per_query ):\n",
    "                        query_ids = ','.join( c[start : start+retrieve_per_query] )\n",
    "                        r = Entrez.read( Entrez.elink( dbfrom=\"pmc\", db=\"pubmed\", LinkName=\"pmc_pubmed\", from_uid=query_ids ) )\n",
    "                        # select the IDs. If no matching PubMed ID was found, [] is returned instead\n",
    "                        p.extend( [] if r[0]['LinkSetDb']==[] else [ int(link['Id']) for link in r[0]['LinkSetDb'][0]['Link'] ] )\n",
    "                    c = p\n",
    "            \n",
    "            except http.client.BadStatusLine:\n",
    "                # Presumably, the server closed the connection before sending a valid response. Retry until we have the data.\n",
    "                print('r')\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        Citations.append( (pm_id, c) )\n",
    "        if (i % 10000 == 0):\n",
    "            print('')\n",
    "            print(i, end='')\n",
    "        if (i % 100 == 0):\n",
    "            print('.', end='')\n",
    "        i += 1\n",
    "        \n",
    "        if i % checkpoint == 0:\n",
    "            print('\\tsaving at checkpoint', i)\n",
    "            pickle.dump( Citations, bz2.BZ2File( Citations_file, 'wb' ) )\n",
    "    \n",
    "    print('\\n done.')\n",
    "    \n",
    "    # Save Citations, as a dictionary indexed by Ids\n",
    "    Citations = dict( Citations )\n",
    "    \n",
    "    pickle.dump( Citations, bz2.BZ2File( Citations_file, 'wb' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that we have indeed obtained the data we expected, you can match the ids below, with the ids listed at the end of last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citations[29052630]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we go from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code above generates multiple local files, containing the datasets we'll be working with. Loading them into memory is a matter of just issuing a call like<br>\n",
    "``data = pickle.load( bz2.BZ2File( data_file, 'rb' ) )``.\n",
    "\n",
    "The Entrez module will therefore no longer be needed, unless you wish to extend your data processing with additional information retrieved from PubMed.\n",
    "\n",
    "Should you be interested in looking at alternative ways to handle the data, have a look at the [sqlite3](http://docs.python.org/3/library/sqlite3.html) module included in Python's standard library, or [Pandas](http://pandas.pydata.org/), the Python Data Analysis Library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
